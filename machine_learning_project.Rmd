---
title: 'Machine Learning: Course Project'
author: "Jeremy Peters"
date: "February 5, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require("knitr")
#opts_knit$set(root.dir = "C:/JP Docs/Data Science Certification/WD/")
```

### Executive Summary
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. In a study, Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).Only Class A corresponds to correct performance. The objective of this  project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to build a machine learning algorithm to predict the manner/class type in which an exerise was completed. More information  about the study and data set can be found in the section on the Weight Lifting Exercise Dataset at the following URL: http://groupware.les.inf.puc-rio.br/har. 

### Exploratory Data Analysis
* The training data for this project was download from the following URL: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv 
* The test data for this project was download from the following URL: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
* Load the required r packages: caret, gbm and randomForest
* Read  the Training and Testing CSV  files in table format, specify types of missing values (NA, empty strings and div0), and create  data frames 
* Display the internal structure of an R object and generate summary statistics of the training dataset
* The Training dataset contains 160 variables and 19,622 records
* The Testing  dataset contains 160 variables and 20 records
* classe is the outcome factor variable with 5 levels: Class A, Class B, Class C, Class D, and Class E
```{r dataanalysis,  echo  =  TRUE}

# Load the required r packages
library(caret)
library(randomForest)
library(gbm)

dfTrain <- read.csv("pml-training.csv", header = TRUE, na.strings=c("NA","#DIV/0!",""))
dfTest <- read.csv("pml-testing.csv", header = TRUE, na.strings=c("NA","#DIV/0!",""))

# Get variable names
names(dfTrain)

str(dfTrain)
dim(dfTest)

#summary(dfTrain)
summary(dfTrain$classe)

```

### Data Processing: Cleaning and Preparation
* Remove the first seven descriptive variables/fields (X/Id, user_name,raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window) from both data sets that will not help predict the manner in which an exercise was completed.
* Remove the variables/fields from the data set that contain missing values
* Remove Near Zero Variance Variables 
* The resulting Training and Testing datasets both have 53 variables/fields the last of which is the classe variable/field
* Cross-validation is performed by splitting the cleaned training data set  into a training data set (75%) that will be used for prediction and a testing/validation data set (25%) that will be used to determine  out-of-sample errors
```{r dataprocessing,  echo  =  TRUE}

dfTrain <- dfTrain[, -c(1:7)]
dfTest <- dfTest[, -c(1:7)]


dfTrain <- dfTrain[, colSums(is.na(dfTrain)) == 0]
dfTest <- dfTest[, colSums(is.na(dfTest)) == 0]

#Remove any Near Zero Variance Variables 
nzVar <- nearZeroVar(dfTrain, saveMetrics = TRUE)
nzVar
dfTrain <- dfTrain[, !nzVar$nzv]
dfTest <- dfTest[, !nzVar$nzv]
dim(dfTrain)

dfInTrain <- createDataPartition(dfTrain$classe, p = 0.75, list = FALSE)
dfPredict <- dfTrain[dfInTrain, ]
dfValidate <- dfTrain[-dfInTrain, ]

```


### Model Fitting
* Random Forest and Stochastic Gradient Boosting Predictive models are fitted  to predict the manner/class type in which an exerise was completed because they are usually the top performing algorithms. see Appendix for Stochastic Gradient Boosting model fitting 
* set.seed for pseudo-random number generation in order to  ensure reproducible results
* Prediction evaluation will maximimize accuracy and minimize out-of sample error
* Random Forest algorithm  was selected  because it is one of the most accurate learning algorithms available and determines the features that are important for classification for many datasets. It works well with a large number of variables where the interactions between variables are unknown. It provides estimates of what variables are important in the classification and handles  correlated covariates & outliers.
* 10-fold cross validation (cv) resampling method is applied to the Random Forest algorithm by default
* The results are predicted using the validation data set 
* The results are compared using a confusionMatrix:  a cross-tabulation of observed and predicted classes with associated statistics.
* The accuracy/overall agreement rate and Kappa are computed 
* The importance of Top 20 Variables are calculated and plotted
```{r modelfitting,  echo  =  TRUE}

set.seed(25)

#fitControl <- trainControl(method='cv', number = 10)
#modFitRf<- train(classe ~ ., data = dfPredict, method = "rf", trControl = fitControl)
modFitRf<- train(classe ~ ., data = dfPredict, method = "rf")
modFitRf
predictRf <- predict(modFitRf, dfValidate)
confusionMatrix(dfValidate$classe, predictRf)
accuracy1 <- postResample(predictRf, dfValidate$classe)
accuracy1

#Calculate the variable importance
modFitRfvarImp <- varImp(modFitRf)
plot(modFitRfvarImp, main = "Importance of Top 20 Variables", top = 20)

```

### Conclusions & Test Data Set Prediction
* The Random Forest algorithm performed very well and gave the best result with an accuracy of 0.992 where accuracy is the proportion of correctly classified observations in the cross-validation test data set. The expected out-of-sample error rate is estimated at 0.008 (1 - accuracy) to represent the the expected misclassified observations in the test data set.
* Therefore, the Random Forest predictive model is applied to the 20 test cases available in the origninal test data set (not cross-validation test data set) .  We can expect that few of the test samples will be misclassified based on the  accuracy shown on the cross-validation data set.
* 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
* B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 

```{r testdatasetprediction,  echo  =  TRUE}

predictRf <- predict(modFitRf, dfTest)
predictRf
```
### Appendix
* Stochastic Gradient Boosting Predictive models is fitted  to predict the manner/class type in which an exerise was completed
* The results are predicted using the validation data set 
* The results are compared using a confusionMatrix:  a cross-tabulation of observed and predicted classes with associated statistics.
* The accuracy/overall agreement rate and Kappa are computed 

```{r modelfittingappendix,  echo  =  TRUE}

modFitGbm<- train(classe ~ ., data = dfPredict, method = "gbm")
predictGbm <- predict(modFitGbm, dfValidate)
confusionMatrix(dfValidate$classe, predictGbm)
accuracy2 <- postResample(predictGbm, dfValidate$classe)
accuracy2

```